{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "953d84f9",
   "metadata": {},
   "source": [
    "Implementation inspired by: https://www.kaggle.com/code/yassineghouzam/introduction-to-cnn-keras-0-997-top-6"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53dabb4e",
   "metadata": {},
   "source": [
    "# 0. Import packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "19ae897c-3ca9-4900-9123-ca596635414f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt \n",
    "import tensorflow\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import Sequential\n",
    "from tensorflow.keras.layers import Dense,Flatten\n",
    "from keras.utils.np_utils import to_categorical # convert to one-hot-encoding\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Flatten, Conv2D, MaxPool2D\n",
    "from keras.optimizers import RMSprop\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.callbacks import ReduceLROnPlateau"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "745cf49e-61f2-49f7-9212-5f910cac609b",
   "metadata": {},
   "source": [
    "# 1. Data preparation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e46973e",
   "metadata": {},
   "source": [
    "## 1.1 Loading the data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29ab580c",
   "metadata": {},
   "source": [
    "#### Load the set of images and labels from the mnist dataset using Keras:\n",
    "* When loading the dataset this way, it already is split into a training set (60000 images) and test set (10000)\n",
    "* The dataset does not contain any missing values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "57551257-0adb-47bb-a9a6-8631db4e3f33",
   "metadata": {},
   "outputs": [],
   "source": [
    "(X_train,y_train),(X_test,y_test)=keras.datasets.mnist.load_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85fc1cb9",
   "metadata": {},
   "source": [
    "#### Displaying some of the images:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "6c008811",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1200x400 with 6 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Display a few example images\n",
    "plt.figure(figsize=(12, 4))\n",
    "\n",
    "for i in range(6):\n",
    "    plt.subplot(2, 3, i + 1)\n",
    "    plt.imshow(X_train[i], cmap='gray')\n",
    "    plt.title(f\"Label: {y_train[i]}\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf16f1b9",
   "metadata": {},
   "source": [
    "#### Reshape the images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "61c31292",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60000, 28, 28)\n",
      "(60000, 28, 28, 1)\n"
     ]
    }
   ],
   "source": [
    "print(X_train.shape)\n",
    "X_train = X_train.reshape(X_train.shape[0], 28, 28, 1)\n",
    "X_test = X_test.reshape(X_test.shape[0], 28, 28, 1)\n",
    "print(X_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "cc8a4d98",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[  0],\n",
       "        [  0],\n",
       "        [  0],\n",
       "        [  0],\n",
       "        [  0],\n",
       "        [  0],\n",
       "        [  0],\n",
       "        [  0],\n",
       "        [  0],\n",
       "        [  0],\n",
       "        [  0],\n",
       "        [  0],\n",
       "        [  0],\n",
       "        [  0],\n",
       "        [  0],\n",
       "        [  0],\n",
       "        [  0],\n",
       "        [  0],\n",
       "        [  0],\n",
       "        [  0],\n",
       "        [  0],\n",
       "        [  0],\n",
       "        [  0],\n",
       "        [  0],\n",
       "        [  0],\n",
       "        [  0],\n",
       "        [  0],\n",
       "        [  0]],\n",
       "\n",
       "       [[  0],\n",
       "        [  0],\n",
       "        [  0],\n",
       "        [  0],\n",
       "        [  0],\n",
       "        [  0],\n",
       "        [  0],\n",
       "        [  0],\n",
       "        [  0],\n",
       "        [  0],\n",
       "        [  0],\n",
       "        [  0],\n",
       "        [  0],\n",
       "        [  0],\n",
       "        [  0],\n",
       "        [  0],\n",
       "        [  0],\n",
       "        [  0],\n",
       "        [  0],\n",
       "        [  0],\n",
       "        [  0],\n",
       "        [  0],\n",
       "        [  0],\n",
       "        [  0],\n",
       "        [  0],\n",
       "        [  0],\n",
       "        [  0],\n",
       "        [  0]],\n",
       "\n",
       "       [[  0],\n",
       "        [  0],\n",
       "        [  0],\n",
       "        [  0],\n",
       "        [  0],\n",
       "        [  0],\n",
       "        [  0],\n",
       "        [  0],\n",
       "        [  0],\n",
       "        [  0],\n",
       "        [  0],\n",
       "        [  0],\n",
       "        [  0],\n",
       "        [  0],\n",
       "        [  0],\n",
       "        [  0],\n",
       "        [  0],\n",
       "        [  0],\n",
       "        [  0],\n",
       "        [  0],\n",
       "        [  0],\n",
       "        [  0],\n",
       "        [  0],\n",
       "        [  0],\n",
       "        [  0],\n",
       "        [  0],\n",
       "        [  0],\n",
       "        [  0]],\n",
       "\n",
       "       [[  0],\n",
       "        [  0],\n",
       "        [  0],\n",
       "        [  0],\n",
       "        [  0],\n",
       "        [  0],\n",
       "        [  0],\n",
       "        [  0],\n",
       "        [  0],\n",
       "        [  0],\n",
       "        [  0],\n",
       "        [  0],\n",
       "        [  0],\n",
       "        [  0],\n",
       "        [  0],\n",
       "        [  0],\n",
       "        [  0],\n",
       "        [  0],\n",
       "        [  0],\n",
       "        [  0],\n",
       "        [  0],\n",
       "        [  0],\n",
       "        [  0],\n",
       "        [  0],\n",
       "        [  0],\n",
       "        [  0],\n",
       "        [  0],\n",
       "        [  0]],\n",
       "\n",
       "       [[  0],\n",
       "        [  0],\n",
       "        [  0],\n",
       "        [  0],\n",
       "        [  0],\n",
       "        [  0],\n",
       "        [  0],\n",
       "        [  0],\n",
       "        [  0],\n",
       "        [  0],\n",
       "        [  0],\n",
       "        [  0],\n",
       "        [  0],\n",
       "        [  0],\n",
       "        [  0],\n",
       "        [  0],\n",
       "        [  0],\n",
       "        [  0],\n",
       "        [  0],\n",
       "        [  0],\n",
       "        [  0],\n",
       "        [  0],\n",
       "        [  0],\n",
       "        [  0],\n",
       "        [  0],\n",
       "        [  0],\n",
       "        [  0],\n",
       "        [  0]],\n",
       "\n",
       "       [[  0],\n",
       "        [  0],\n",
       "        [  0],\n",
       "        [  0],\n",
       "        [  0],\n",
       "        [  0],\n",
       "        [  0],\n",
       "        [  0],\n",
       "        [  0],\n",
       "        [  0],\n",
       "        [  0],\n",
       "        [  0],\n",
       "        [  3],\n",
       "        [ 18],\n",
       "        [ 18],\n",
       "        [ 18],\n",
       "        [126],\n",
       "        [136],\n",
       "        [175],\n",
       "        [ 26],\n",
       "        [166],\n",
       "        [255],\n",
       "        [247],\n",
       "        [127],\n",
       "        [  0],\n",
       "        [  0],\n",
       "        [  0],\n",
       "        [  0]],\n",
       "\n",
       "       [[  0],\n",
       "        [  0],\n",
       "        [  0],\n",
       "        [  0],\n",
       "        [  0],\n",
       "        [  0],\n",
       "        [  0],\n",
       "        [  0],\n",
       "        [ 30],\n",
       "        [ 36],\n",
       "        [ 94],\n",
       "        [154],\n",
       "        [170],\n",
       "        [253],\n",
       "        [253],\n",
       "        [253],\n",
       "        [253],\n",
       "        [253],\n",
       "        [225],\n",
       "        [172],\n",
       "        [253],\n",
       "        [242],\n",
       "        [195],\n",
       "        [ 64],\n",
       "        [  0],\n",
       "        [  0],\n",
       "        [  0],\n",
       "        [  0]],\n",
       "\n",
       "       [[  0],\n",
       "        [  0],\n",
       "        [  0],\n",
       "        [  0],\n",
       "        [  0],\n",
       "        [  0],\n",
       "        [  0],\n",
       "        [ 49],\n",
       "        [238],\n",
       "        [253],\n",
       "        [253],\n",
       "        [253],\n",
       "        [253],\n",
       "        [253],\n",
       "        [253],\n",
       "        [253],\n",
       "        [253],\n",
       "        [251],\n",
       "        [ 93],\n",
       "        [ 82],\n",
       "        [ 82],\n",
       "        [ 56],\n",
       "        [ 39],\n",
       "        [  0],\n",
       "        [  0],\n",
       "        [  0],\n",
       "        [  0],\n",
       "        [  0]],\n",
       "\n",
       "       [[  0],\n",
       "        [  0],\n",
       "        [  0],\n",
       "        [  0],\n",
       "        [  0],\n",
       "        [  0],\n",
       "        [  0],\n",
       "        [ 18],\n",
       "        [219],\n",
       "        [253],\n",
       "        [253],\n",
       "        [253],\n",
       "        [253],\n",
       "        [253],\n",
       "        [198],\n",
       "        [182],\n",
       "        [247],\n",
       "        [241],\n",
       "        [  0],\n",
       "        [  0],\n",
       "        [  0],\n",
       "        [  0],\n",
       "        [  0],\n",
       "        [  0],\n",
       "        [  0],\n",
       "        [  0],\n",
       "        [  0],\n",
       "        [  0]],\n",
       "\n",
       "       [[  0],\n",
       "        [  0],\n",
       "        [  0],\n",
       "        [  0],\n",
       "        [  0],\n",
       "        [  0],\n",
       "        [  0],\n",
       "        [  0],\n",
       "        [ 80],\n",
       "        [156],\n",
       "        [107],\n",
       "        [253],\n",
       "        [253],\n",
       "        [205],\n",
       "        [ 11],\n",
       "        [  0],\n",
       "        [ 43],\n",
       "        [154],\n",
       "        [  0],\n",
       "        [  0],\n",
       "        [  0],\n",
       "        [  0],\n",
       "        [  0],\n",
       "        [  0],\n",
       "        [  0],\n",
       "        [  0],\n",
       "        [  0],\n",
       "        [  0]],\n",
       "\n",
       "       [[  0],\n",
       "        [  0],\n",
       "        [  0],\n",
       "        [  0],\n",
       "        [  0],\n",
       "        [  0],\n",
       "        [  0],\n",
       "        [  0],\n",
       "        [  0],\n",
       "        [ 14],\n",
       "        [  1],\n",
       "        [154],\n",
       "        [253],\n",
       "        [ 90],\n",
       "        [  0],\n",
       "        [  0],\n",
       "        [  0],\n",
       "        [  0],\n",
       "        [  0],\n",
       "        [  0],\n",
       "        [  0],\n",
       "        [  0],\n",
       "        [  0],\n",
       "        [  0],\n",
       "        [  0],\n",
       "        [  0],\n",
       "        [  0],\n",
       "        [  0]],\n",
       "\n",
       "       [[  0],\n",
       "        [  0],\n",
       "        [  0],\n",
       "        [  0],\n",
       "        [  0],\n",
       "        [  0],\n",
       "        [  0],\n",
       "        [  0],\n",
       "        [  0],\n",
       "        [  0],\n",
       "        [  0],\n",
       "        [139],\n",
       "        [253],\n",
       "        [190],\n",
       "        [  2],\n",
       "        [  0],\n",
       "        [  0],\n",
       "        [  0],\n",
       "        [  0],\n",
       "        [  0],\n",
       "        [  0],\n",
       "        [  0],\n",
       "        [  0],\n",
       "        [  0],\n",
       "        [  0],\n",
       "        [  0],\n",
       "        [  0],\n",
       "        [  0]],\n",
       "\n",
       "       [[  0],\n",
       "        [  0],\n",
       "        [  0],\n",
       "        [  0],\n",
       "        [  0],\n",
       "        [  0],\n",
       "        [  0],\n",
       "        [  0],\n",
       "        [  0],\n",
       "        [  0],\n",
       "        [  0],\n",
       "        [ 11],\n",
       "        [190],\n",
       "        [253],\n",
       "        [ 70],\n",
       "        [  0],\n",
       "        [  0],\n",
       "        [  0],\n",
       "        [  0],\n",
       "        [  0],\n",
       "        [  0],\n",
       "        [  0],\n",
       "        [  0],\n",
       "        [  0],\n",
       "        [  0],\n",
       "        [  0],\n",
       "        [  0],\n",
       "        [  0]],\n",
       "\n",
       "       [[  0],\n",
       "        [  0],\n",
       "        [  0],\n",
       "        [  0],\n",
       "        [  0],\n",
       "        [  0],\n",
       "        [  0],\n",
       "        [  0],\n",
       "        [  0],\n",
       "        [  0],\n",
       "        [  0],\n",
       "        [  0],\n",
       "        [ 35],\n",
       "        [241],\n",
       "        [225],\n",
       "        [160],\n",
       "        [108],\n",
       "        [  1],\n",
       "        [  0],\n",
       "        [  0],\n",
       "        [  0],\n",
       "        [  0],\n",
       "        [  0],\n",
       "        [  0],\n",
       "        [  0],\n",
       "        [  0],\n",
       "        [  0],\n",
       "        [  0]],\n",
       "\n",
       "       [[  0],\n",
       "        [  0],\n",
       "        [  0],\n",
       "        [  0],\n",
       "        [  0],\n",
       "        [  0],\n",
       "        [  0],\n",
       "        [  0],\n",
       "        [  0],\n",
       "        [  0],\n",
       "        [  0],\n",
       "        [  0],\n",
       "        [  0],\n",
       "        [ 81],\n",
       "        [240],\n",
       "        [253],\n",
       "        [253],\n",
       "        [119],\n",
       "        [ 25],\n",
       "        [  0],\n",
       "        [  0],\n",
       "        [  0],\n",
       "        [  0],\n",
       "        [  0],\n",
       "        [  0],\n",
       "        [  0],\n",
       "        [  0],\n",
       "        [  0]],\n",
       "\n",
       "       [[  0],\n",
       "        [  0],\n",
       "        [  0],\n",
       "        [  0],\n",
       "        [  0],\n",
       "        [  0],\n",
       "        [  0],\n",
       "        [  0],\n",
       "        [  0],\n",
       "        [  0],\n",
       "        [  0],\n",
       "        [  0],\n",
       "        [  0],\n",
       "        [  0],\n",
       "        [ 45],\n",
       "        [186],\n",
       "        [253],\n",
       "        [253],\n",
       "        [150],\n",
       "        [ 27],\n",
       "        [  0],\n",
       "        [  0],\n",
       "        [  0],\n",
       "        [  0],\n",
       "        [  0],\n",
       "        [  0],\n",
       "        [  0],\n",
       "        [  0]],\n",
       "\n",
       "       [[  0],\n",
       "        [  0],\n",
       "        [  0],\n",
       "        [  0],\n",
       "        [  0],\n",
       "        [  0],\n",
       "        [  0],\n",
       "        [  0],\n",
       "        [  0],\n",
       "        [  0],\n",
       "        [  0],\n",
       "        [  0],\n",
       "        [  0],\n",
       "        [  0],\n",
       "        [  0],\n",
       "        [ 16],\n",
       "        [ 93],\n",
       "        [252],\n",
       "        [253],\n",
       "        [187],\n",
       "        [  0],\n",
       "        [  0],\n",
       "        [  0],\n",
       "        [  0],\n",
       "        [  0],\n",
       "        [  0],\n",
       "        [  0],\n",
       "        [  0]],\n",
       "\n",
       "       [[  0],\n",
       "        [  0],\n",
       "        [  0],\n",
       "        [  0],\n",
       "        [  0],\n",
       "        [  0],\n",
       "        [  0],\n",
       "        [  0],\n",
       "        [  0],\n",
       "        [  0],\n",
       "        [  0],\n",
       "        [  0],\n",
       "        [  0],\n",
       "        [  0],\n",
       "        [  0],\n",
       "        [  0],\n",
       "        [  0],\n",
       "        [249],\n",
       "        [253],\n",
       "        [249],\n",
       "        [ 64],\n",
       "        [  0],\n",
       "        [  0],\n",
       "        [  0],\n",
       "        [  0],\n",
       "        [  0],\n",
       "        [  0],\n",
       "        [  0]],\n",
       "\n",
       "       [[  0],\n",
       "        [  0],\n",
       "        [  0],\n",
       "        [  0],\n",
       "        [  0],\n",
       "        [  0],\n",
       "        [  0],\n",
       "        [  0],\n",
       "        [  0],\n",
       "        [  0],\n",
       "        [  0],\n",
       "        [  0],\n",
       "        [  0],\n",
       "        [  0],\n",
       "        [ 46],\n",
       "        [130],\n",
       "        [183],\n",
       "        [253],\n",
       "        [253],\n",
       "        [207],\n",
       "        [  2],\n",
       "        [  0],\n",
       "        [  0],\n",
       "        [  0],\n",
       "        [  0],\n",
       "        [  0],\n",
       "        [  0],\n",
       "        [  0]],\n",
       "\n",
       "       [[  0],\n",
       "        [  0],\n",
       "        [  0],\n",
       "        [  0],\n",
       "        [  0],\n",
       "        [  0],\n",
       "        [  0],\n",
       "        [  0],\n",
       "        [  0],\n",
       "        [  0],\n",
       "        [  0],\n",
       "        [  0],\n",
       "        [ 39],\n",
       "        [148],\n",
       "        [229],\n",
       "        [253],\n",
       "        [253],\n",
       "        [253],\n",
       "        [250],\n",
       "        [182],\n",
       "        [  0],\n",
       "        [  0],\n",
       "        [  0],\n",
       "        [  0],\n",
       "        [  0],\n",
       "        [  0],\n",
       "        [  0],\n",
       "        [  0]],\n",
       "\n",
       "       [[  0],\n",
       "        [  0],\n",
       "        [  0],\n",
       "        [  0],\n",
       "        [  0],\n",
       "        [  0],\n",
       "        [  0],\n",
       "        [  0],\n",
       "        [  0],\n",
       "        [  0],\n",
       "        [ 24],\n",
       "        [114],\n",
       "        [221],\n",
       "        [253],\n",
       "        [253],\n",
       "        [253],\n",
       "        [253],\n",
       "        [201],\n",
       "        [ 78],\n",
       "        [  0],\n",
       "        [  0],\n",
       "        [  0],\n",
       "        [  0],\n",
       "        [  0],\n",
       "        [  0],\n",
       "        [  0],\n",
       "        [  0],\n",
       "        [  0]],\n",
       "\n",
       "       [[  0],\n",
       "        [  0],\n",
       "        [  0],\n",
       "        [  0],\n",
       "        [  0],\n",
       "        [  0],\n",
       "        [  0],\n",
       "        [  0],\n",
       "        [ 23],\n",
       "        [ 66],\n",
       "        [213],\n",
       "        [253],\n",
       "        [253],\n",
       "        [253],\n",
       "        [253],\n",
       "        [198],\n",
       "        [ 81],\n",
       "        [  2],\n",
       "        [  0],\n",
       "        [  0],\n",
       "        [  0],\n",
       "        [  0],\n",
       "        [  0],\n",
       "        [  0],\n",
       "        [  0],\n",
       "        [  0],\n",
       "        [  0],\n",
       "        [  0]],\n",
       "\n",
       "       [[  0],\n",
       "        [  0],\n",
       "        [  0],\n",
       "        [  0],\n",
       "        [  0],\n",
       "        [  0],\n",
       "        [ 18],\n",
       "        [171],\n",
       "        [219],\n",
       "        [253],\n",
       "        [253],\n",
       "        [253],\n",
       "        [253],\n",
       "        [195],\n",
       "        [ 80],\n",
       "        [  9],\n",
       "        [  0],\n",
       "        [  0],\n",
       "        [  0],\n",
       "        [  0],\n",
       "        [  0],\n",
       "        [  0],\n",
       "        [  0],\n",
       "        [  0],\n",
       "        [  0],\n",
       "        [  0],\n",
       "        [  0],\n",
       "        [  0]],\n",
       "\n",
       "       [[  0],\n",
       "        [  0],\n",
       "        [  0],\n",
       "        [  0],\n",
       "        [ 55],\n",
       "        [172],\n",
       "        [226],\n",
       "        [253],\n",
       "        [253],\n",
       "        [253],\n",
       "        [253],\n",
       "        [244],\n",
       "        [133],\n",
       "        [ 11],\n",
       "        [  0],\n",
       "        [  0],\n",
       "        [  0],\n",
       "        [  0],\n",
       "        [  0],\n",
       "        [  0],\n",
       "        [  0],\n",
       "        [  0],\n",
       "        [  0],\n",
       "        [  0],\n",
       "        [  0],\n",
       "        [  0],\n",
       "        [  0],\n",
       "        [  0]],\n",
       "\n",
       "       [[  0],\n",
       "        [  0],\n",
       "        [  0],\n",
       "        [  0],\n",
       "        [136],\n",
       "        [253],\n",
       "        [253],\n",
       "        [253],\n",
       "        [212],\n",
       "        [135],\n",
       "        [132],\n",
       "        [ 16],\n",
       "        [  0],\n",
       "        [  0],\n",
       "        [  0],\n",
       "        [  0],\n",
       "        [  0],\n",
       "        [  0],\n",
       "        [  0],\n",
       "        [  0],\n",
       "        [  0],\n",
       "        [  0],\n",
       "        [  0],\n",
       "        [  0],\n",
       "        [  0],\n",
       "        [  0],\n",
       "        [  0],\n",
       "        [  0]],\n",
       "\n",
       "       [[  0],\n",
       "        [  0],\n",
       "        [  0],\n",
       "        [  0],\n",
       "        [  0],\n",
       "        [  0],\n",
       "        [  0],\n",
       "        [  0],\n",
       "        [  0],\n",
       "        [  0],\n",
       "        [  0],\n",
       "        [  0],\n",
       "        [  0],\n",
       "        [  0],\n",
       "        [  0],\n",
       "        [  0],\n",
       "        [  0],\n",
       "        [  0],\n",
       "        [  0],\n",
       "        [  0],\n",
       "        [  0],\n",
       "        [  0],\n",
       "        [  0],\n",
       "        [  0],\n",
       "        [  0],\n",
       "        [  0],\n",
       "        [  0],\n",
       "        [  0]],\n",
       "\n",
       "       [[  0],\n",
       "        [  0],\n",
       "        [  0],\n",
       "        [  0],\n",
       "        [  0],\n",
       "        [  0],\n",
       "        [  0],\n",
       "        [  0],\n",
       "        [  0],\n",
       "        [  0],\n",
       "        [  0],\n",
       "        [  0],\n",
       "        [  0],\n",
       "        [  0],\n",
       "        [  0],\n",
       "        [  0],\n",
       "        [  0],\n",
       "        [  0],\n",
       "        [  0],\n",
       "        [  0],\n",
       "        [  0],\n",
       "        [  0],\n",
       "        [  0],\n",
       "        [  0],\n",
       "        [  0],\n",
       "        [  0],\n",
       "        [  0],\n",
       "        [  0]],\n",
       "\n",
       "       [[  0],\n",
       "        [  0],\n",
       "        [  0],\n",
       "        [  0],\n",
       "        [  0],\n",
       "        [  0],\n",
       "        [  0],\n",
       "        [  0],\n",
       "        [  0],\n",
       "        [  0],\n",
       "        [  0],\n",
       "        [  0],\n",
       "        [  0],\n",
       "        [  0],\n",
       "        [  0],\n",
       "        [  0],\n",
       "        [  0],\n",
       "        [  0],\n",
       "        [  0],\n",
       "        [  0],\n",
       "        [  0],\n",
       "        [  0],\n",
       "        [  0],\n",
       "        [  0],\n",
       "        [  0],\n",
       "        [  0],\n",
       "        [  0],\n",
       "        [  0]]], dtype=uint8)"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "216be7b2",
   "metadata": {},
   "source": [
    "#### Normalize images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "5c2c3fe7",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = X_train.astype('float32') / 255\n",
    "X_test = X_test.astype('float32') / 255"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d471991",
   "metadata": {},
   "source": [
    "#### Label encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "a25c6dd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = to_categorical(y_train, num_classes = 10)\n",
    "y_test = to_categorical(y_test, num_classes = 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "7ff21bc9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60000, 10)"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a88ab72",
   "metadata": {},
   "source": [
    "#### Things to consider in this section:\n",
    "* Reshaping the data (the data needs to be in a specific format before entering the model)\n",
    "* Label encoding\n",
    "* etc."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59ddef30-fb04-463c-8fa6-6a028e340483",
   "metadata": {},
   "source": [
    "## 1.2 Data Augmentation\n",
    "Apply techniques to diversify the diversity of our training data. Could for instance be: \n",
    "* Normalizing the images (for instance grayscale normalization)\n",
    "* horizontal or vertical flips\n",
    "* random crops \n",
    "* color jitters\n",
    "* translations\n",
    "* and more..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "775e1527-a26b-43c9-a133-0083fcab2a8b",
   "metadata": {},
   "source": [
    "# 2. CNN"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1525d8c4",
   "metadata": {},
   "source": [
    "## 2.1 Defining the model\n",
    "* Define all the layers, including Conv2D (convolutional layers), MaxPool2D (pooling layers), dropout layers, flatten layer and dense layer\n",
    "* Decide upon things like the optimizer, loss function, batch size, number of epochs and so on. Maybe introduce early stopping (a mechanism that makes the training of the network stop automatically once the value of the loss starts increasing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "525da54e",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "\n",
    "model.add(Conv2D(filters = 32, kernel_size = (5,5),padding = 'Same', \n",
    "                 activation ='relu', input_shape = (28,28,1)))\n",
    "model.add(Conv2D(filters = 32, kernel_size = (5,5),padding = 'Same', \n",
    "                 activation ='relu'))\n",
    "model.add(MaxPool2D(pool_size=(2,2)))\n",
    "model.add(Dropout(0.25))\n",
    "\n",
    "\n",
    "model.add(Conv2D(filters = 64, kernel_size = (3,3),padding = 'Same', \n",
    "                 activation ='relu'))\n",
    "model.add(Conv2D(filters = 64, kernel_size = (3,3),padding = 'Same', \n",
    "                 activation ='relu'))\n",
    "model.add(MaxPool2D(pool_size=(2,2), strides=(2,2)))\n",
    "model.add(Dropout(0.25))\n",
    "\n",
    "\n",
    "model.add(Flatten())\n",
    "model.add(Dense(256, activation = \"relu\"))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(10, activation = \"softmax\"))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e3a797a",
   "metadata": {},
   "source": [
    "#### Set optimizer and compile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "cd34220a",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = RMSprop(lr=0.001, rho=0.9, epsilon=1e-08, decay=0.0)\n",
    "model.compile(optimizer = optimizer , loss = \"categorical_crossentropy\", metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b463606",
   "metadata": {},
   "source": [
    "#### Set batch size and epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "55a2ae9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 1 # Turn epochs to 30 to get 0.9967 accuracy\n",
    "batch_size = 86"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7817fdf9",
   "metadata": {},
   "source": [
    "# 3. Data augmentation and train"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d85c9605",
   "metadata": {},
   "source": [
    "#### Data augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "0a40ac9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# With data augmentation to prevent overfitting (accuracy 0.99286)\n",
    "\n",
    "datagen = ImageDataGenerator(\n",
    "        featurewise_center=False,  # set input mean to 0 over the dataset\n",
    "        samplewise_center=False,  # set each sample mean to 0\n",
    "        featurewise_std_normalization=False,  # divide inputs by std of the dataset\n",
    "        samplewise_std_normalization=False,  # divide each input by its std\n",
    "        zca_whitening=False,  # apply ZCA whitening\n",
    "        rotation_range=10,  # randomly rotate images in the range (degrees, 0 to 180)\n",
    "        zoom_range = 0.1, # Randomly zoom image \n",
    "        width_shift_range=0.1,  # randomly shift images horizontally (fraction of total width)\n",
    "        height_shift_range=0.1,  # randomly shift images vertically (fraction of total height)\n",
    "        horizontal_flip=False,  # randomly flip images\n",
    "        vertical_flip=False)  # randomly flip images\n",
    "\n",
    "\n",
    "datagen.fit(X_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7d05a5e",
   "metadata": {},
   "source": [
    "#### Train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "a0548b02",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "697/697 [==============================] - ETA: 0s - loss: 0.1340 - accuracy: 0.9596"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "in user code:\n\n    File \"C:\\Users\\Magnus\\.conda\\envs\\Bachelor\\lib\\site-packages\\keras\\engine\\training.py\", line 1727, in test_function  *\n        return step_function(self, iterator)\n    File \"C:\\Users\\Magnus\\.conda\\envs\\Bachelor\\lib\\site-packages\\keras\\engine\\training.py\", line 1713, in step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"C:\\Users\\Magnus\\.conda\\envs\\Bachelor\\lib\\site-packages\\keras\\engine\\training.py\", line 1701, in run_step  **\n        outputs = model.test_step(data)\n    File \"C:\\Users\\Magnus\\.conda\\envs\\Bachelor\\lib\\site-packages\\keras\\engine\\training.py\", line 1667, in test_step\n        self.compute_loss(x, y, y_pred, sample_weight)\n    File \"C:\\Users\\Magnus\\.conda\\envs\\Bachelor\\lib\\site-packages\\keras\\engine\\training.py\", line 1052, in compute_loss\n        return self.compiled_loss(\n    File \"C:\\Users\\Magnus\\.conda\\envs\\Bachelor\\lib\\site-packages\\keras\\engine\\compile_utils.py\", line 265, in __call__\n        loss_value = loss_obj(y_t, y_p, sample_weight=sw)\n    File \"C:\\Users\\Magnus\\.conda\\envs\\Bachelor\\lib\\site-packages\\keras\\losses.py\", line 152, in __call__\n        losses = call_fn(y_true, y_pred)\n    File \"C:\\Users\\Magnus\\.conda\\envs\\Bachelor\\lib\\site-packages\\keras\\losses.py\", line 272, in call  **\n        return ag_fn(y_true, y_pred, **self._fn_kwargs)\n    File \"C:\\Users\\Magnus\\.conda\\envs\\Bachelor\\lib\\site-packages\\keras\\losses.py\", line 1990, in categorical_crossentropy\n        return backend.categorical_crossentropy(\n    File \"C:\\Users\\Magnus\\.conda\\envs\\Bachelor\\lib\\site-packages\\keras\\backend.py\", line 5529, in categorical_crossentropy\n        target.shape.assert_is_compatible_with(output.shape)\n\n    ValueError: Shapes (None, 1) and (None, 10) are incompatible\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[67], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m history \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdatagen\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mflow\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43mY_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbatch_size\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m      2\u001b[0m \u001b[43m                              \u001b[49m\u001b[43mepochs\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mepochs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalidation_data\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_test\u001b[49m\u001b[43m,\u001b[49m\u001b[43my_test\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m      3\u001b[0m \u001b[43m                              \u001b[49m\u001b[43mverbose\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msteps_per_epoch\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mX_train\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mshape\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m/\u001b[39;49m\u001b[38;5;241;43m/\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\.conda\\envs\\Bachelor\\lib\\site-packages\\keras\\utils\\traceback_utils.py:70\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     67\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[0;32m     68\u001b[0m     \u001b[38;5;66;03m# To get the full stack trace, call:\u001b[39;00m\n\u001b[0;32m     69\u001b[0m     \u001b[38;5;66;03m# `tf.debugging.disable_traceback_filtering()`\u001b[39;00m\n\u001b[1;32m---> 70\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28mNone\u001b[39m\n\u001b[0;32m     71\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m     72\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[1;32m~\\AppData\\Local\\Temp\\__autograph_generated_file60jqm0uz.py:15\u001b[0m, in \u001b[0;36mouter_factory.<locals>.inner_factory.<locals>.tf__test_function\u001b[1;34m(iterator)\u001b[0m\n\u001b[0;32m     13\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m     14\u001b[0m     do_return \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m---> 15\u001b[0m     retval_ \u001b[38;5;241m=\u001b[39m ag__\u001b[38;5;241m.\u001b[39mconverted_call(ag__\u001b[38;5;241m.\u001b[39mld(step_function), (ag__\u001b[38;5;241m.\u001b[39mld(\u001b[38;5;28mself\u001b[39m), ag__\u001b[38;5;241m.\u001b[39mld(iterator)), \u001b[38;5;28;01mNone\u001b[39;00m, fscope)\n\u001b[0;32m     16\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m:\n\u001b[0;32m     17\u001b[0m     do_return \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n",
      "\u001b[1;31mValueError\u001b[0m: in user code:\n\n    File \"C:\\Users\\Magnus\\.conda\\envs\\Bachelor\\lib\\site-packages\\keras\\engine\\training.py\", line 1727, in test_function  *\n        return step_function(self, iterator)\n    File \"C:\\Users\\Magnus\\.conda\\envs\\Bachelor\\lib\\site-packages\\keras\\engine\\training.py\", line 1713, in step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"C:\\Users\\Magnus\\.conda\\envs\\Bachelor\\lib\\site-packages\\keras\\engine\\training.py\", line 1701, in run_step  **\n        outputs = model.test_step(data)\n    File \"C:\\Users\\Magnus\\.conda\\envs\\Bachelor\\lib\\site-packages\\keras\\engine\\training.py\", line 1667, in test_step\n        self.compute_loss(x, y, y_pred, sample_weight)\n    File \"C:\\Users\\Magnus\\.conda\\envs\\Bachelor\\lib\\site-packages\\keras\\engine\\training.py\", line 1052, in compute_loss\n        return self.compiled_loss(\n    File \"C:\\Users\\Magnus\\.conda\\envs\\Bachelor\\lib\\site-packages\\keras\\engine\\compile_utils.py\", line 265, in __call__\n        loss_value = loss_obj(y_t, y_p, sample_weight=sw)\n    File \"C:\\Users\\Magnus\\.conda\\envs\\Bachelor\\lib\\site-packages\\keras\\losses.py\", line 152, in __call__\n        losses = call_fn(y_true, y_pred)\n    File \"C:\\Users\\Magnus\\.conda\\envs\\Bachelor\\lib\\site-packages\\keras\\losses.py\", line 272, in call  **\n        return ag_fn(y_true, y_pred, **self._fn_kwargs)\n    File \"C:\\Users\\Magnus\\.conda\\envs\\Bachelor\\lib\\site-packages\\keras\\losses.py\", line 1990, in categorical_crossentropy\n        return backend.categorical_crossentropy(\n    File \"C:\\Users\\Magnus\\.conda\\envs\\Bachelor\\lib\\site-packages\\keras\\backend.py\", line 5529, in categorical_crossentropy\n        target.shape.assert_is_compatible_with(output.shape)\n\n    ValueError: Shapes (None, 1) and (None, 10) are incompatible\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(datagen.flow(X_train,Y_train, batch_size=batch_size),\n",
    "                              epochs = epochs, validation_data = (X_test,y_test),\n",
    "                              verbose = 1, steps_per_epoch=X_train.shape[0] // batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "6be8feb2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 13/698 [..............................] - ETA: 6:10 - loss: 0.5050 - accuracy: 0.8676"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[66], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m history \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepochs\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mepochs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[0;32m      2\u001b[0m \u001b[43m          \u001b[49m\u001b[43mvalidation_data\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_test\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_test\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mverbose\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\.conda\\envs\\Bachelor\\lib\\site-packages\\keras\\utils\\traceback_utils.py:65\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     63\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m     64\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m---> 65\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m fn(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m     66\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m     67\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[1;32m~\\.conda\\envs\\Bachelor\\lib\\site-packages\\keras\\engine\\training.py:1564\u001b[0m, in \u001b[0;36mModel.fit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m   1556\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m tf\u001b[38;5;241m.\u001b[39mprofiler\u001b[38;5;241m.\u001b[39mexperimental\u001b[38;5;241m.\u001b[39mTrace(\n\u001b[0;32m   1557\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtrain\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m   1558\u001b[0m     epoch_num\u001b[38;5;241m=\u001b[39mepoch,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1561\u001b[0m     _r\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m,\n\u001b[0;32m   1562\u001b[0m ):\n\u001b[0;32m   1563\u001b[0m     callbacks\u001b[38;5;241m.\u001b[39mon_train_batch_begin(step)\n\u001b[1;32m-> 1564\u001b[0m     tmp_logs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain_function\u001b[49m\u001b[43m(\u001b[49m\u001b[43miterator\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1565\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m data_handler\u001b[38;5;241m.\u001b[39mshould_sync:\n\u001b[0;32m   1566\u001b[0m         context\u001b[38;5;241m.\u001b[39masync_wait()\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\tensorflow\\python\\util\\traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    148\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    149\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 150\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m fn(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    151\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    152\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\tensorflow\\python\\eager\\def_function.py:915\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    912\u001b[0m compiler \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mxla\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnonXla\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    914\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m OptionalXlaContext(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile):\n\u001b[1;32m--> 915\u001b[0m   result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)\n\u001b[0;32m    917\u001b[0m new_tracing_count \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexperimental_get_tracing_count()\n\u001b[0;32m    918\u001b[0m without_tracing \u001b[38;5;241m=\u001b[39m (tracing_count \u001b[38;5;241m==\u001b[39m new_tracing_count)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\tensorflow\\python\\eager\\def_function.py:947\u001b[0m, in \u001b[0;36mFunction._call\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    944\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock\u001b[38;5;241m.\u001b[39mrelease()\n\u001b[0;32m    945\u001b[0m   \u001b[38;5;66;03m# In this case we have created variables on the first call, so we run the\u001b[39;00m\n\u001b[0;32m    946\u001b[0m   \u001b[38;5;66;03m# defunned version which is guaranteed to never create variables.\u001b[39;00m\n\u001b[1;32m--> 947\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_stateless_fn(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)  \u001b[38;5;66;03m# pylint: disable=not-callable\u001b[39;00m\n\u001b[0;32m    948\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_stateful_fn \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    949\u001b[0m   \u001b[38;5;66;03m# Release the lock early so that multiple threads can perform the call\u001b[39;00m\n\u001b[0;32m    950\u001b[0m   \u001b[38;5;66;03m# in parallel.\u001b[39;00m\n\u001b[0;32m    951\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock\u001b[38;5;241m.\u001b[39mrelease()\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\tensorflow\\python\\eager\\function.py:2496\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   2493\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock:\n\u001b[0;32m   2494\u001b[0m   (graph_function,\n\u001b[0;32m   2495\u001b[0m    filtered_flat_args) \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_maybe_define_function(args, kwargs)\n\u001b[1;32m-> 2496\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mgraph_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_flat\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   2497\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfiltered_flat_args\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcaptured_inputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgraph_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcaptured_inputs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\tensorflow\\python\\eager\\function.py:1862\u001b[0m, in \u001b[0;36mConcreteFunction._call_flat\u001b[1;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[0;32m   1858\u001b[0m possible_gradient_type \u001b[38;5;241m=\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPossibleTapeGradientTypes(args)\n\u001b[0;32m   1859\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (possible_gradient_type \u001b[38;5;241m==\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPOSSIBLE_GRADIENT_TYPES_NONE\n\u001b[0;32m   1860\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m executing_eagerly):\n\u001b[0;32m   1861\u001b[0m   \u001b[38;5;66;03m# No tape is watching; skip to running the function.\u001b[39;00m\n\u001b[1;32m-> 1862\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_build_call_outputs(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_inference_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1863\u001b[0m \u001b[43m      \u001b[49m\u001b[43mctx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcancellation_manager\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcancellation_manager\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[0;32m   1864\u001b[0m forward_backward \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_select_forward_and_backward_functions(\n\u001b[0;32m   1865\u001b[0m     args,\n\u001b[0;32m   1866\u001b[0m     possible_gradient_type,\n\u001b[0;32m   1867\u001b[0m     executing_eagerly)\n\u001b[0;32m   1868\u001b[0m forward_function, args_with_tangents \u001b[38;5;241m=\u001b[39m forward_backward\u001b[38;5;241m.\u001b[39mforward()\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\tensorflow\\python\\eager\\function.py:499\u001b[0m, in \u001b[0;36m_EagerDefinedFunction.call\u001b[1;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[0;32m    497\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m _InterpolateFunctionError(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m    498\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m cancellation_manager \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m--> 499\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m \u001b[43mexecute\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexecute\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    500\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mstr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msignature\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    501\u001b[0m \u001b[43m        \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_num_outputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    502\u001b[0m \u001b[43m        \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    503\u001b[0m \u001b[43m        \u001b[49m\u001b[43mattrs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    504\u001b[0m \u001b[43m        \u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mctx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    505\u001b[0m   \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    506\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m execute\u001b[38;5;241m.\u001b[39mexecute_with_cancellation(\n\u001b[0;32m    507\u001b[0m         \u001b[38;5;28mstr\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msignature\u001b[38;5;241m.\u001b[39mname),\n\u001b[0;32m    508\u001b[0m         num_outputs\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_outputs,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    511\u001b[0m         ctx\u001b[38;5;241m=\u001b[39mctx,\n\u001b[0;32m    512\u001b[0m         cancellation_manager\u001b[38;5;241m=\u001b[39mcancellation_manager)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\tensorflow\\python\\eager\\execute.py:54\u001b[0m, in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     52\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m     53\u001b[0m   ctx\u001b[38;5;241m.\u001b[39mensure_initialized()\n\u001b[1;32m---> 54\u001b[0m   tensors \u001b[38;5;241m=\u001b[39m \u001b[43mpywrap_tfe\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mTFE_Py_Execute\u001b[49m\u001b[43m(\u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_handle\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mop_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     55\u001b[0m \u001b[43m                                      \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     56\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m core\u001b[38;5;241m.\u001b[39m_NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m     57\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "history = model.fit(X_train, y_train, batch_size = batch_size, epochs = epochs, \n",
    "          validation_data = (X_test, y_test), verbose = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02a1646d",
   "metadata": {},
   "source": [
    "## 2.2 Tuning the model - Magnus\n",
    "We can tune are model to make sure that the hyperparameters we have chosen ensures opimal performance. Some hyperparameters that could be useful to tune (according to ChatGPT) are:\n",
    "* Number of Convolutional layers\n",
    "* Number of Filters\n",
    "* Filter Size (Kernel Size)\n",
    "* Pooling\n",
    "* Dropout Rate\n",
    "* Weight Initialization\n",
    "* Data Augmentation\n",
    "* and more..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "687d32a9-ced8-43e1-bb7c-ff8beede1c1f",
   "metadata": {},
   "source": [
    "# 3. Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60f0e0a0",
   "metadata": {},
   "source": [
    "#### Plotting training and validation loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf2a216d",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(2,1)\n",
    "ax[0].plot(history.history['loss'], color='b', label=\"Training loss\")\n",
    "ax[0].plot(history.history['val_loss'], color='r', label=\"validation loss\",axes =ax[0])\n",
    "legend = ax[0].legend(loc='best', shadow=True)\n",
    "\n",
    "ax[1].plot(history.history['acc'], color='b', label=\"Training accuracy\")\n",
    "ax[1].plot(history.history['val_acc'], color='r',label=\"Validation accuracy\")\n",
    "legend = ax[1].legend(loc='best', shadow=True"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2991103",
   "metadata": {},
   "source": [
    "#### Confusion matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b5200b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_confusion_matrix(cm, classes,\n",
    "                          normalize=False,\n",
    "                          title='Confusion matrix',\n",
    "                          cmap=plt.cm.Blues):\n",
    "    \"\"\"\n",
    "    This function prints and plots the confusion matrix.\n",
    "    Normalization can be applied by setting `normalize=True`.\n",
    "    \"\"\"\n",
    "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
    "    plt.title(title)\n",
    "    plt.colorbar()\n",
    "    tick_marks = np.arange(len(classes))\n",
    "    plt.xticks(tick_marks, classes, rotation=45)\n",
    "    plt.yticks(tick_marks, classes)\n",
    "    if normalize:\n",
    "        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "\n",
    "    thresh = cm.max() / 2.\n",
    "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
    "        plt.text(j, i, cm[i, j],\n",
    "                 horizontalalignment=\"center\",\n",
    "                 color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.ylabel('True label')\n",
    "    plt.xlabel('Predicted label')\n",
    "\n",
    "# Predict the values from the validation dataset\n",
    "Y_pred = model.predict(X_val)\n",
    "# Convert predictions classes to one hot vectors \n",
    "Y_pred_classes = np.argmax(Y_pred,axis = 1) \n",
    "# Convert validation observations to one hot vectors\n",
    "Y_true = np.argmax(Y_val,axis = 1) \n",
    "# compute the confusion matrix\n",
    "confusion_mtx = confusion_matrix(Y_true, Y_pred_classes) \n",
    "# plot the confusion matrix\n",
    "plot_confusion_matrix(confusion_mtx, classes = range(10)) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe3d0f60",
   "metadata": {},
   "source": [
    "In the example, they have used these techniques to evaluate the model:\n",
    "* Training and validation curves\n",
    "* Confusion matrix\n",
    "* Displaying errors "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ddf1f6d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
